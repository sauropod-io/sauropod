use anyhow::Context as _;
use axum::response::sse::Event as SseEvent;
use axum::{response::IntoResponse, response::Sse};

use sauropod_openai_api::{
    CreateResponse, Response, ResponseError, ResponseErrorCode, ResponseStatus,
};

mod routes;
pub use routes::*;

/// A generated response and the data used to create it.
#[derive(Clone)]
struct ResponseData {
    /// The inputs used to create the response.
    input: Option<sauropod_openai_api::CreateResponseInput>,
    /// The response generated by the model.
    response: Response,
}

/// Create a `Response` with an error message.
fn response_with_error(
    request: &CreateResponse,
    message: String,
) -> axum::Json<sauropod_openai_api::Response> {
    let mut response = sauropod_inference_engine_api::make_response(request);
    response.status = Some(ResponseStatus::Failed);
    response.error = Some(ResponseError {
        message,
        code: ResponseErrorCode::ServerError,
    });
    axum::Json(response)
}

/// Merge the current request with the previous responses.
///
/// The responses in `previous` are ordered from the most recent to the oldest.
fn merge_responses(request: &mut CreateResponse, previous: Vec<ResponseData>) {
    // If no instructions are provided in the request, try to use the instructions from the previous responses.
    if request.instructions.is_none() {
        request.instructions = previous
            .iter()
            .find_map(|x| match &x.response.instructions {
                Some(sauropod_openai_api::ResponseInstructions::Variant0(instructions)) => {
                    Some(instructions.clone())
                }
                Some(sauropod_openai_api::ResponseInstructions::Variant1(_)) => {
                    panic!("Item-based instructions are not supported yet")
                }
                None => None,
            });
    }

    let mut messages = Vec::new();
    for response in previous.into_iter().rev() {
        match response.input {
            Some(sauropod_openai_api::CreateResponseInput::Variant0(content)) => {
                messages.push(sauropod_openai_api::InputItem::EasyInputMessage(
                    sauropod_openai_api::EasyInputMessage {
                        content: sauropod_openai_api::EasyInputMessageContent::Variant0(
                            content.clone(),
                        ),
                        role: sauropod_openai_api::EasyInputMessageRole::User,
                        r#type: Some(sauropod_openai_api::EasyInputMessageType::Message),
                    },
                ));
            }
            Some(sauropod_openai_api::CreateResponseInput::Variant1(items)) => {
                messages.extend(items.iter().cloned());
            }
            None => {}
        }
        for output in response.response.output {
            messages.push(sauropod_openai_api::InputItem::Item(output.into()));
        }
    }

    match &request.input {
        Some(sauropod_openai_api::CreateResponseInput::Variant0(content)) => {
            messages.push(sauropod_openai_api::InputItem::EasyInputMessage(
                sauropod_openai_api::EasyInputMessage {
                    content: sauropod_openai_api::EasyInputMessageContent::Variant0(
                        content.clone(),
                    ),
                    role: sauropod_openai_api::EasyInputMessageRole::User,
                    r#type: Some(sauropod_openai_api::EasyInputMessageType::Message),
                },
            ));
        }
        Some(sauropod_openai_api::CreateResponseInput::Variant1(items)) => {
            messages.extend(items.iter().cloned());
        }
        None => {}
    }

    request.input = Some(sauropod_openai_api::CreateResponseInput::Variant1(messages));
}

async fn store_response(
    global_state: std::sync::Arc<sauropod_global_state::GlobalState>,
    previous_response_id: Option<&str>,
    response_input: Option<&sauropod_openai_api::CreateResponseInput>,
    response: &sauropod_openai_api::Response,
    authentication: &sauropod_inference_http::Authentication,
) -> anyhow::Result<()> {
    let request_text = serde_json::to_string(&response_input)?;
    let response_text = serde_json::to_string(&response)?;
    let user_id = authentication.get_user_id();
    let _ = sqlx::query!(
        "INSERT INTO response (response_id, parent_response_id, user_id, response_request, response_output) VALUES (?1, ?2, ?3, ?4, ?5)",
        response.id,
        previous_response_id,
        user_id,
        request_text,
        response_text
    )
    .execute(global_state.database())
    .await?;
    Ok(())
}

async fn get_response_chain(
    previous_response_id: &str,
    user_id: sauropod_users::UserId,
    global_state: &sauropod_global_state::GlobalState,
) -> anyhow::Result<Vec<ResponseData>> {
    let parent_chain = sqlx::query_file!("queries/parent_chain.sql", previous_response_id, user_id)
        .fetch_all(global_state.database())
        .await?;
    let mut result = Vec::with_capacity(parent_chain.len());
    for row in parent_chain.into_iter() {
        let response_output =
            serde_json::from_str(&row.response_output).context("Deserializing response output")?;
        let response_input =
            serde_json::from_str(&row.response_request).context("Deserializing response input")?;
        result.push(ResponseData {
            input: response_input,
            response: response_output,
        });
    }

    Ok(result)
}

pub async fn create_response_impl(
    global_state: std::sync::Arc<sauropod_global_state::GlobalState>,
    request: CreateResponse,
    authentication: sauropod_inference_http::Authentication,
) -> anyhow::Result<axum::response::Response> {
    tracing::debug!("create response request: {:#?}", request);
    let model_name = match serde_json::to_value(&request.response_properties.model) {
        Ok(serde_json::Value::String(model_name)) => model_name,
        Ok(x) => {
            return Ok(
                response_with_error(&request, format!("Invalid model name: {x}")).into_response(),
            );
        }
        Err(e) => {
            return Ok(
                response_with_error(&request, format!("Invalid model name: {e}")).into_response(),
            );
        }
    };

    let Some(model) = global_state.get_model(&model_name).await else {
        return Ok(
            response_with_error(&request, format!("Model '{model_name}' not found"))
                .into_response(),
        );
    };

    let previous_responses = if let Some(previous_response_id) =
        request.response_properties.previous_response_id.as_deref()
    {
        let previous_responses = get_response_chain(
            previous_response_id,
            authentication.get_user_id(),
            &global_state,
        )
        .await?;
        if previous_responses.is_empty() {
            return Ok(response_with_error(
                &request,
                format!("Previous response with ID '{previous_response_id}' not found"),
            )
            .into_response());
        }
        previous_responses
    } else {
        Vec::new()
    };

    let mut merged_request = request.clone();
    merge_responses(&mut merged_request, previous_responses);
    let render_context = sauropod_prompt_templates::RenderContext::from_create_response(
        &merged_request,
        model.get_system_prompt(),
    )?;

    tracing::debug!("Merged request: {:#?}", merged_request);

    let store = request.store.unwrap_or(false);
    if request.stream.unwrap_or(false) {
        let event_stream = model
            .generate_stream(request.clone(), render_context)
            .await?;
        let mapped_stream = async_stream::stream! {
            for await event in event_stream {
                match event {
                    Ok(sauropod_openai_api::ResponseStreamEvent::ResponseCompletedEvent {
                        response,
                        sequence_number,
                    }) => {
                        // Store the response if requested
                        if store {
                            store_response(global_state.clone(),request.response_properties.previous_response_id.as_deref(), request.input.as_ref(), &response, &authentication).await?;
                        }

                        yield Ok(SseEvent::default()
                            .json_data(
                                sauropod_openai_api::ResponseStreamEvent::ResponseCompletedEvent {
                                    response,
                                    sequence_number,
                                },
                            ).unwrap())
                    }

                    Ok(data) => yield Ok(SseEvent::default().json_data(data).unwrap()),
                    Err(e) => yield Err(e),
                }
            }
        };
        Ok(Sse::new(mapped_stream).into_response())
    } else {
        let response = model.generate(request.clone(), render_context).await?;

        // Store the response if requested
        if store {
            store_response(
                global_state,
                request.response_properties.previous_response_id.as_deref(),
                request.input.as_ref(),
                &response,
                &authentication,
            )
            .await?;
        }

        Ok(axum::Json(response).into_response())
    }
}
